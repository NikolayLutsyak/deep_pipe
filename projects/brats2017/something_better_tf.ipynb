{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "from imp import reload\n",
    "from os.path import join\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_loader import Brats\n",
    "import medim\n",
    "from models_tf import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_msegm2015(s):\n",
    "    r = np.zeros((3, *s.shape), dtype=bool)\n",
    "    r[0] = s > 0\n",
    "    r[1] = (s == 1) | (s == 3) | (s == 4)\n",
    "    r[2] = (s == 4)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [00:42<00:00,  6.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_path = '/home/mount/neuro-x02-ssd/brats2015/processed'\n",
    "encode_msegm = encode_msegm2015\n",
    "\n",
    "data_loader = Brats(processed_path)\n",
    "patients = data_loader.patients\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for patient in tqdm(patients):\n",
    "    x.append(data_loader.load_mscan(patient))\n",
    "    y.append(data_loader.load_segm(patient))\n",
    "\n",
    "n_modalities = 4\n",
    "n_msegm_chans = 3\n",
    "n_classes = len(np.unique(y[0]))\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_splits_train = 5\n",
    "n_splits_val = 40\n",
    "\n",
    "cv = KFold(n_splits_train, shuffle=True, random_state=42)\n",
    "train, test = next(cv.split(y))\n",
    "\n",
    "def extract(l, idx):\n",
    "    return [l[i] for i in idx]\n",
    "\n",
    "x_train, x_test = extract(x, train), extract(x, test)\n",
    "y_train, y_test = extract(y, train), extract(y, test)\n",
    "\n",
    "cv = KFold(n_splits_val, shuffle=True, random_state=21)\n",
    "train, val = next(cv.split(x_train))\n",
    "\n",
    "x_train, x_val = extract(x_train, train), extract(x_train, val)\n",
    "y_train, y_val = extract(y_train, train), extract(y_train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "blocks = [n_modalities, 32, 32, 64, 64]\n",
    "\n",
    "patch_size_x = np.array([25, 25, 25])\n",
    "patch_size_y = patch_size_x - 2*(len(blocks) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 352 ms, sys: 4.68 s, total: 5.03 s\n",
      "Wall time: 4.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "padding = (patch_size_x - patch_size_y) // 2\n",
    "\n",
    "val_shape = np.max(list(map(np.shape, x_val)), axis=0)[1:]\n",
    "\n",
    "def min_padding(x, padding, val_shape):\n",
    "    # 3-dimentional spatial\n",
    "    non_spatial = x.ndim - 3\n",
    "    padding = np.array(padding)\n",
    "    \n",
    "    padding = list(zip(padding, padding + val_shape - np.array(x.shape[non_spatial:])))\n",
    "    padding = [(0, 0)] * non_spatial + padding\n",
    "    \n",
    "    return np.pad(x, padding, mode='constant')\n",
    "\n",
    "x_val_padded = [min_padding(s, padding, val_shape) for s in x_val]\n",
    "y_val_padded = [min_padding(s, [0, 0, 0], val_shape) for s in y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = EEnet(blocks, n_classes, kernel_size)\n",
    "\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_path = '/tmp/tf'\n",
    "train_operation = make_training_operation(model, log_path)\n",
    "val_operation = make_validation_operation(model, log_path)\n",
    "\n",
    "session = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, batch_iter, lr, n_batches):\n",
    "    losses = []\n",
    "    for _ in tqdm(range(n_batches)):\n",
    "        x_batch, y_batch = next(batch_iter)\n",
    "        y_batch = np.int64(y_batch)\n",
    "        \n",
    "        loss = train_operation(x_batch, y_batch, lr, session)\n",
    "        losses.append(loss)\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "def predict_evaluate(model, x, y):\n",
    "    y_pred, losses = [], []\n",
    "    for xo, yo in tqdm(zip(x, y)):\n",
    "        x_batch = xo[None, :]\n",
    "        y_batch = np.int64(yo[None, :])\n",
    "        yo_pred, loss = val_operation(x_batch, y_batch, session)\n",
    "        y_pred.append(yo_pred)\n",
    "        losses.append(loss)\n",
    "    return y_pred, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:17<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.323581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:03,  1.84it/s]\n",
      "6it [00:01,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val       : 0.0620192\n",
      "Val dices : [ 0.05997261  0.          0.        ]\n",
      "\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 40/40 [00:16<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0866656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:03,  1.92it/s]\n",
      "6it [00:01,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val       : 0.0535373\n",
      "Val dices : [ 0.05997261  0.          0.        ]\n",
      "\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 40/40 [00:16<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0924303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:03,  1.96it/s]\n",
      "6it [00:01,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val       : 0.0582572\n",
      "Val dices : [ 0.05997261  0.          0.        ]\n",
      "\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 40/40 [00:16<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0826762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:03,  1.83it/s]\n",
      "6it [00:01,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val       : 0.0498347\n",
      "Val dices : [ 0.05997261  0.          0.        ]\n",
      "\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 40/40 [00:16<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0814916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:03,  1.91it/s]\n",
      "6it [00:01,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val       : 0.053347\n",
      "Val dices : [ 0.05997261  0.          0.        ]\n",
      "\n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 40/40 [00:16<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0751868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:03,  1.79it/s]\n",
      "6it [00:01,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val       : 0.0557734\n",
      "Val dices : [ 0.05997261  0.          0.        ]\n",
      "\n",
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 40/40 [00:16<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0697552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:03,  1.92it/s]\n",
      "6it [00:01,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val       : 0.0469683\n",
      "Val dices : [ 0.05997261  0.          0.        ]\n",
      "\n",
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 40/40 [00:16<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.07682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:03,  1.84it/s]\n",
      "6it [00:01,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val       : 0.043166\n",
      "Val dices : [ 0.05997261  0.          0.        ]\n",
      "\n",
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 40/40 [00:16<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0689402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:03,  1.95it/s]\n",
      "6it [00:01,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val       : 0.0415084\n",
      "Val dices : [ 0.05997261  0.          0.        ]\n",
      "\n",
      "\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 40/40 [00:16<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0705614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:03,  1.81it/s]\n",
      "6it [00:01,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val       : 0.0444832\n",
      "Val dices : [ 0.05997261  0.          0.        ]\n",
      "\n",
      "\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 6/40 [00:02<00:14,  2.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-940ff2e736c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-2d34cbb9b6b4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, batch_iter, lr, n_batches)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/medim/projects/brats2017/models_tf/operations.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(x_batch, y_batch, lr, session)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             {model.x_ph: x_batch, model.y_ph: y_batch,\n\u001b[0;32m---> 14\u001b[0;31m              model.lr: lr, model.is_training: True})\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "\n",
    "n_epoch = 100\n",
    "n_batches_per_epoch = 40\n",
    "\n",
    "train_iter = medim.batch_iter.patch.uniform(\n",
    "        [x_train, y_train], [patch_size_x, patch_size_y], batch_size=batch_size,\n",
    "        spatial_dims=(-3, -2, -1), \n",
    "    )\n",
    "    \n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    print('Epoch {}'.format(epoch), flush=True)\n",
    "    \n",
    "    train_loss = train(model, train_iter, lr, n_batches_per_epoch)\n",
    "    print('Train:', train_loss, flush=True)\n",
    "    \n",
    "    losses = []\n",
    "    dices = []\n",
    "    \n",
    "    y_pred, losses = predict_evaluate(model, x_val_padded, y_val_padded)\n",
    "    \n",
    "    dices = []\n",
    "    for yo_pred, yo_true in tqdm(zip(y_pred, y_val_padded)):\n",
    "        msegm_true = encode_msegm(yo_true)\n",
    "        msegm_pred = encode_msegm(yo_pred)\n",
    "        dices.append([medim.metrics.dice_score(msegm_pred[k], msegm_true[k])\n",
    "                      for k in range(n_msegm_chans)])\n",
    "    \n",
    "    val_loss = np.mean(losses)\n",
    "    val_dices = np.mean(dices, axis=0)\n",
    "\n",
    "    print('Val       :', val_loss)\n",
    "    print('Val dices :', val_dices)\n",
    "    print('\\n', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 632 ms, sys: 852 ms, total: 1.48 s\n",
      "Wall time: 1.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9770362883573271"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "segm_log_loss(yo_pred, yo_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93480953059053296"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.argmax(yo_pred, axis=0) == yo_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_msegm_chans = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_parts = [1, 2, 1]\n",
    "\n",
    "n_epoch = 100\n",
    "batch_per_epoch = 40\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    train_iter = medim.batch_iter.patch.uniform(\n",
    "        x_train, x_train, batch_size=batch_size,\n",
    "        patch_size_x=patch_size_x, patch_size_y=patch_size_y, \n",
    "    )\n",
    "    \n",
    "    start_train = time.time()\n",
    "    \n",
    "    losses = []\n",
    "    for _ in tqdm(range(batch_per_epoch)):\n",
    "        x_batch, y_batch = next(train_iter)\n",
    "    \n",
    "    end_train = time.time()\n",
    "    train_loss = np.mean(losses)\n",
    "    \n",
    "    print('Epoch {}'.format(epoch), flush=True)\n",
    "    \n",
    "    start_val = time.time()\n",
    "    \n",
    "    losses = []\n",
    "    dices = []\n",
    "\n",
    "    for mscan, msegm in zip(x_val_padded, y_val_padded):\n",
    "        msegm = np.array(msegm, dtype=np.float32)\n",
    "\n",
    "        mscan_parts = medim.utils.divide(mscan, padding, n_parts)\n",
    "        msegm_parts = medim.utils.divide(msegm, [0, 0, 0], n_parts)\n",
    "\n",
    "        predicted = []\n",
    "        true = []\n",
    "        for mscan_part, msegm_part in tqdm(zip(mscan_parts, msegm_parts)):\n",
    "            o = np.array(mscan_part[None, :])\n",
    "\n",
    "            y_pred = np.array(msegm_part)\n",
    "\n",
    "            predicted.append(y_pred)\n",
    "            true.append(msegm_part)\n",
    "    \n",
    "        y_pred = combine_fast(predicted)\n",
    "        y_true = combine_fast(true)\n",
    "        \n",
    "        #dices.append([dice_score(y_pred[k] > 0.5, y_true[k]) for k in range(n_classes)])\n",
    "    \n",
    "    end_val = time.time()\n",
    "    \n",
    "    val_loss = np.mean(losses)\n",
    "    val_dices = np.mean(dices, axis=0)\n",
    "\n",
    "    print('Time :', end_train - start_train, end_val - start_val)\n",
    "    print('\\n', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "\n",
    "model.eval()\n",
    "for mscan, msegm in tqdm(zip(x_val_padded, y_val)):\n",
    "    msegm = np.array(msegm, dtype=np.float32)\n",
    "\n",
    "    mscan_parts = medim.utils.divide(mscan, padding, n_parts)\n",
    "    msegm_parts = medim.utils.divide(msegm, [0, 0, 0], n_parts)\n",
    "\n",
    "    predicted = []\n",
    "    for mscan_part, msegm_part in zip(mscan_parts, msegm_parts):\n",
    "        o = np.array(mscan_part[None, :])\n",
    "\n",
    "        y_pred = model(to_var(o, volatile=True))\n",
    "        loss = F.binary_cross_entropy(y_pred, to_var(msegm_part[None, :], volatile=True))\n",
    "        \n",
    "        predicted.append(to_numpy(y_pred)[0])\n",
    "\n",
    "    y_pred = medim.utils.combine(predicted, n_parts)\n",
    "    y_preds.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dice_threshold(y_preds, my):\n",
    "    thresholds = []\n",
    "    for i in range(n_classes):\n",
    "        ps = np.linspace(0, 1, 100)\n",
    "        best_p = 0\n",
    "        best_score = 0\n",
    "        for p in ps:\n",
    "            score = np.mean([dice_score(pred[i] > p, true[i]) for pred, true in zip(y_preds, my)])\n",
    "            if score is np.nan or None:\n",
    "                print('None')\n",
    "                score = 1\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_p = p\n",
    "                best_score = score\n",
    "        thresholds.append(best_p)\n",
    "        print(best_score)\n",
    "    return thresholds\n",
    "\n",
    "thresholds = get_dice_threshold(y_preds, y_val)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_preds_t = []\n",
    "\n",
    "model.eval()\n",
    "for mscan, msegm in tqdm(zip(x_test, y_test)):\n",
    "    mscan = min_padding(mscan, padding)\n",
    "    msegm = np.array(msegm, dtype=np.float32)\n",
    "\n",
    "    mscan_parts = medim.utils.divide(mscan, padding, n_parts)\n",
    "    msegm_parts = medim.utils.divide(msegm, [0, 0, 0], n_parts)\n",
    "\n",
    "    predicted = []\n",
    "    for mscan_part, msegm_part in zip(mscan_parts, msegm_parts):\n",
    "        o = np.array(mscan_part[None, :])\n",
    "\n",
    "        y_pred = model(to_var(o, volatile=True))\n",
    "        loss = F.binary_cross_entropy(y_pred, to_var(msegm_part[None, :], volatile=True))\n",
    "        \n",
    "        predicted.append(to_numpy(y_pred)[0])\n",
    "\n",
    "    y_pred = medim.utils.combine(predicted, n_parts)\n",
    "    y_preds_t.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean([[dice_score(y_preds_t[i][k] > thresholds[k], y_test[i][k]) for k in range(n_classes)]\n",
    "         for i in range(len(y_preds_t))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(x_train), len(x_val), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(15, 15))\n",
    "\n",
    "i = 4\n",
    "k = 90\n",
    "\n",
    "cmap = cm.GnBu\n",
    "fontsize = 30\n",
    "\n",
    "ax[0, 0].set_title('Predicted segmentation', fontsize=fontsize)\n",
    "ax[0, 0].imshow(y_preds_t[i][0, ..., k], cmap=cmap)\n",
    "#plt.colorbar()\n",
    "#plt.show()\n",
    "ax[0, 1].set_title('Ground truth', fontsize=fontsize)\n",
    "ax[0, 1].imshow(y_test[i][0, ..., k], cmap=cmap)\n",
    "\n",
    "ax[1,0].set_title('Brain slice', fontsize=fontsize)\n",
    "ax[1, 0].imshow(x_test[i][3, ..., k], cmap=cmap)\n",
    "plt.tight_layout()\n",
    "ax[0, 0].axis('off')\n",
    "ax[1, 0].axis('off')\n",
    "ax[0, 1].axis('off')\n",
    "ax[1, 1].axis('off')\n",
    "plt.show()\n",
    "#plt.colorbar()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segm_log_loss(yo_pred, yo_true):\n",
    "    y_pred = np.moveaxis(yo_pred, 0, 3).reshape((-1, n_classes))\n",
    "    y_true = yo_true.flatten()\n",
    "    return log_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def pred_reshape(y):\n",
    "#     x = y.permute(0, 2, 3, 4, 1)\n",
    "#     return x.contiguous().view(-1, x.size()[-1])\n",
    "\n",
    "# def loss_cross_entropy(y_pred, y_true):\n",
    "#     return F.cross_entropy(pred_reshape(y_pred), y_true.view(-1))\n",
    "\n",
    "\n",
    "coeff = to_var(np.array([1, 2, 3], dtype=np.float32))\n",
    "epsilon = 1e-7\n",
    "\n",
    "def dice_loss(y_pred, target):\n",
    "    y_pred = y_pred.view(*y_pred.size()[:2], -1)\n",
    "    target = target.view(*target.size()[:2], -1)\n",
    "    \n",
    "#     s = y_pred.size()\n",
    "#     e = epsilon.expand(s[0], 1, s[2])\n",
    "    dice_scores = 2 * (epsilon + (y_pred * target).sum(2)) / \\\n",
    "                  (y_pred.sum(2) + target.sum(2) + 2 * epsilon)\n",
    "        \n",
    "    dice_scores = dice_scores.mean(0)\n",
    "    dice_scores = dice_scores.view(-1)\n",
    "\n",
    "    return -torch.sum(dice_scores * coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_object(model, xo, n_parts_per_axis):\n",
    "    model.eval()\n",
    "    xo_parts = medim.utils.divide(xo, [0] + [*padding], n_parts_per_axis)\n",
    "\n",
    "    xo_predicted = []\n",
    "    for xo_part in xo_parts:\n",
    "        xo_part = xo_part[None, :]\n",
    "\n",
    "        y_pred = model(to_var(xo_part, volatile=True))\n",
    "\n",
    "        xo_predicted.append(to_numpy(y_pred)[0])\n",
    "\n",
    "    yo_pred = medim.utils.combine(xo_predicted, n_parts_per_axis)\n",
    "    return yo_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
