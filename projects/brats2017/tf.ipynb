{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = (28, 28)\n",
    "n_classes = 10\n",
    "\n",
    "imgs_train = mnist.train.images.reshape((-1, 1, *img_size)) / 255\n",
    "imgs_val = mnist.validation.images.reshape((-1, 1, *img_size)) / 255\n",
    "imgs_test = mnist.test.images.reshape((-1, 1, *img_size)) / 255\n",
    "\n",
    "y_train = mnist.train.labels.astype(np.int32)\n",
    "y_val = mnist.validation.labels.astype(np.int32)\n",
    "y_test = mnist.test.labels.astype(np.int32)\n",
    "\n",
    "def make_batch_iter(x, y, batch_size, shuffle=False):\n",
    "    n = len(x)\n",
    "    idx = np.arange(n)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx)\n",
    "    \n",
    "    for i in range(0, n, batch_size):\n",
    "        x_batch = x[i:i+batch_size]\n",
    "        y_batch = y[i:i+batch_size]\n",
    "        yield np.array(x_batch, np.float32), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_fe(l, n_layers, kernel_size, n_chans_base, n_chans_mul):\n",
    "    for i in range(n_layers):\n",
    "        n_chans = n_chans_base * n_chans_mul ** i\n",
    "        l = slim.conv2d(l, n_chans, kernel_size, padding='valid',\n",
    "                        data_format='NCHW', activation_fn=tf.nn.relu,\n",
    "                        normalizer_fn=slim.batch_norm)\n",
    "        l = slim.max_pool2d(l, 2, 2, data_format='NCHW')\n",
    "    l = tf.reduce_mean(l, axis=(2, 3), name='global_average_pooling')\n",
    "    return l\n",
    "\n",
    "def build_clf(l):\n",
    "    n_layers = 2\n",
    "    units = 1024\n",
    "    for i in range(n_layers):\n",
    "        l = slim.relu(l, units, normalizer_fn=slim.batch_norm)\n",
    "    l = slim.fully_connected(l, n_classes, normalizer_fn=slim.batch_norm)\n",
    "    return l\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, n_layers, n_chans_base, n_chans_mul, kernel_size):\n",
    "        self.x_ph = tf.placeholder(tf.float32, (None, 1, None, None))\n",
    "        self.training = tf.placeholder(tf.bool)\n",
    "        self.y_ph = tf.placeholder(tf.int64, (None,))\n",
    "        \n",
    "        with slim.arg_scope([slim.batch_norm], is_training=self.training,\n",
    "                            decay=0.9, data_format='NCHW', fused=True):\n",
    "            self.fe = build_fe(self.x_ph, n_layers, kernel_size,\n",
    "                               n_chans_base, n_chans_mul)\n",
    "            self.logits = build_clf(self.fe)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(self.y_ph, self.logits))\n",
    "        self.acc = tf.contrib.metrics.accuracy(tf.argmax(self.logits, 1), self.y_ph)\n",
    "        \n",
    "        self.train_op = slim.learning.create_train_op(self.loss, tf.train.AdamOptimizer())\n",
    "\n",
    "n_layers = 3\n",
    "kernel_size = 3\n",
    "n_chans_base = 16\n",
    "n_chans_mul = 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "with graph.as_default():\n",
    "    model = Model(n_layers, n_chans_base, n_chans_mul, kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train: 0.689129796488 0.909418182442\n",
      "Val  : 2.6344859848 0.112600002193\n",
      "Time : 3.0514960289001465\n",
      "\n",
      "\n",
      "Epoch 1\n",
      "Train: 0.472594303083 0.971309091819\n",
      "Val  : 0.484376084185 0.973799996567\n",
      "Time : 1.4473044872283936\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "Train: 0.421500842411 0.980036364044\n",
      "Val  : 0.439248408604 0.980199998665\n",
      "Time : 1.450057029724121\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "Train: 0.387938246935 0.98489090851\n",
      "Val  : 0.392955954552 0.98499999218\n",
      "Time : 1.4433908462524414\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Train: 0.362638219842 0.988727272736\n",
      "Val  : 0.356715663624 0.986199982834\n",
      "Time : 1.4462671279907227\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Train: 0.343041778538 0.991000000598\n",
      "Val  : 0.332703485203 0.987599977779\n",
      "Time : 1.4351048469543457\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Train: 0.328456886565 0.992563636962\n",
      "Val  : 0.323737135696 0.987999977779\n",
      "Time : 1.4410545825958252\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Train: 0.317705158958 0.993945455438\n",
      "Val  : 0.320323725128 0.987399977779\n",
      "Time : 1.4476897716522217\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Train: 0.310533735709 0.995127274409\n",
      "Val  : 0.319051664591 0.98819998064\n",
      "Time : 1.4474480152130127\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Train: 0.305789261948 0.996000000893\n",
      "Val  : 0.320083811665 0.987599989986\n",
      "Time : 1.4422881603240967\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Train: 0.302057464738 0.996872727966\n",
      "Val  : 0.317960106325 0.987599987125\n",
      "Time : 1.4414544105529785\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Train: 0.299341560966 0.997400000694\n",
      "Val  : 0.317909905529 0.987599987125\n",
      "Time : 1.4431438446044922\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Train: 0.297145150011 0.997981818381\n",
      "Val  : 0.316715234184 0.987599987125\n",
      "Time : 1.4454317092895508\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Train: 0.295258794707 0.998309091897\n",
      "Val  : 0.314655033207 0.987799987125\n",
      "Time : 1.443124532699585\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Train: 0.293974488449 0.998654545949\n",
      "Val  : 0.314171619797 0.987999987125\n",
      "Time : 1.443359613418579\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Train: 0.292641885506 0.998963636858\n",
      "Val  : 0.314496229649 0.987999977779\n",
      "Time : 1.4428040981292725\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Train: 0.291308808886 0.999127273221\n",
      "Val  : 0.313481258678 0.987399977779\n",
      "Time : 1.4536340236663818\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Train: 0.290221415099 0.999236364131\n",
      "Val  : 0.31369006381 0.987999977779\n",
      "Time : 1.451974630355835\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Train: 0.28942213707 0.999327273221\n",
      "Val  : 0.311464490938 0.987599976349\n",
      "Time : 1.4362666606903076\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Train: 0.288775358092 0.999509091403\n",
      "Val  : 0.311233076811 0.988199977779\n",
      "Time : 1.4410407543182373\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Train: 0.288194606824 0.99954545504\n",
      "Val  : 0.307696052647 0.987999977779\n",
      "Time : 1.449369192123413\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Train: 0.28764033152 0.999600000494\n",
      "Val  : 0.30575549674 0.987999982071\n",
      "Time : 1.444556474685669\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Train: 0.287139782806 0.999636363342\n",
      "Val  : 0.302916458559 0.987999982071\n",
      "Time : 1.4313700199127197\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Train: 0.286775080351 0.999672727767\n",
      "Val  : 0.303888674164 0.987799982071\n",
      "Time : 1.4421486854553223\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Train: 0.286439416898 0.999709091403\n",
      "Val  : 0.302646037388 0.988399982071\n",
      "Time : 1.449209213256836\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Train: 0.286096945316 0.999709091403\n",
      "Val  : 0.302935033607 0.988399982071\n",
      "Time : 1.4440107345581055\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "Train: 0.285766526963 0.999727273221\n",
      "Val  : 0.300906129932 0.98859998064\n",
      "Time : 1.4349079132080078\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "Train: 0.285495430461 0.999781818676\n",
      "Val  : 0.300114550018 0.98819998064\n",
      "Time : 1.441734790802002\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Train: 0.285242907637 0.999818181523\n",
      "Val  : 0.301463443422 0.988199988556\n",
      "Time : 1.4407048225402832\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Train: 0.285042084581 0.999854545949\n",
      "Val  : 0.303362383652 0.986399985695\n",
      "Time : 1.4488263130187988\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "Train: 0.284912417928 0.999854545949\n",
      "Val  : 0.301316809273 0.986199985695\n",
      "Time : 1.4456956386566162\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Train: 0.284795010549 0.999836364131\n",
      "Val  : 0.302463395214 0.986799973488\n",
      "Time : 1.445871114730835\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Train: 0.284553531928 0.999854545949\n",
      "Val  : 0.30373256793 0.987599982834\n",
      "Time : 1.444441795349121\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "Train: 0.284356193248 0.999872727767\n",
      "Val  : 0.308896101475 0.988199985695\n",
      "Time : 1.4419937133789062\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Train: 0.284286295951 0.999872727767\n",
      "Val  : 0.310640701675 0.98939997921\n",
      "Time : 1.4463460445404053\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "Train: 0.284100422556 0.999927273221\n",
      "Val  : 0.314107407904 0.987399977779\n",
      "Time : 1.4470744132995605\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Train: 0.283827060478 0.999927273221\n",
      "Val  : 0.312811098337 0.98879998064\n",
      "Time : 1.4439730644226074\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Train: 0.283556337591 0.999927272433\n",
      "Val  : 0.31672933197 0.987199987125\n",
      "Time : 1.4450013637542725\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Train: 0.283269112201 0.99994545504\n",
      "Val  : 0.318623415661 0.986399974918\n",
      "Time : 1.446808099746704\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8780ad2eae9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mount/neuro-t01-ssd/home/krivov/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epoch = 100\n",
    "batch_size = 1024\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epoch):\n",
    "        train_iter = make_batch_iter(imgs_train, y_train, batch_size=batch_size)\n",
    "        val_iter = make_batch_iter(imgs_val, y_val, batch_size=batch_size)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        losses = []\n",
    "        weights = []\n",
    "        accs = []\n",
    "        for x_batch, y_batch in train_iter:\n",
    "            feed_dict = {model.x_ph: x_batch, model.y_ph: y_batch, model.training: True}\n",
    "            _, loss, acc = session.run([model.train_op, model.loss, model.acc], feed_dict)\n",
    "\n",
    "            accs.append(acc)\n",
    "            losses.append(loss)\n",
    "            weights.append(len(x_batch))\n",
    "\n",
    "        train_loss = np.average(np.array(losses).flatten(), weights=weights)\n",
    "        train_acc = np.average(np.array(accs).flatten(), weights=weights)\n",
    "\n",
    "        losses = []\n",
    "        weights = []\n",
    "        accs = []\n",
    "        for x_batch, y_batch in val_iter:\n",
    "            feed_dict = {model.x_ph: x_batch, model.y_ph: y_batch, model.training: False}\n",
    "            loss, acc = session.run([model.loss, model.acc], feed_dict)\n",
    "\n",
    "            accs.append(acc)\n",
    "            losses.append(loss)\n",
    "            weights.append(len(x_batch))\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        val_loss = np.average(np.array(losses).flatten(), weights=weights)\n",
    "        val_acc = np.average(np.array(accs).flatten(), weights=weights)\n",
    "\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        print('Train:', train_loss, train_acc)\n",
    "        print('Val  :', val_loss, val_acc)\n",
    "        print('Time :', end - start)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
