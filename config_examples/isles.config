dataset = dataset_wrapper.cached
    dataset = dataset.isles2017
        data_path = "/nmnt/x04-hdd/ISLES/"
        metadata_rpath = "isles2017_crop.csv"

train_ids = meta.from_json
    path = train_ids_path
val_ids = meta.from_json
    path = val_ids_path
ids = meta.from_json
    path = ids_path

experiment = experiment.flat
    makefile = "train_msegm_threshold_eval"
    config_path = config_path
    experiment_path = experiment_path
    split = split.cv_111
        n_splits = 5
        val_size = 5
        dataset = dataset

load_x = meta.extractor
    property = "load_mscan"
    module = dataset

load_y = meta.extractor
    property = "load_msegm"
    module = dataset

batch_size = 20
batch_iter_factory = batch_iter_factory.fin
    get_batch_iter = batch_iter.slices
        @init = false
        ids = train_ids
        load_x = load_x
        load_y = load_y

        batch_size = batch_size
        shuffle = true

model_core = model_core.uresnet2d
    channels = [32 64]

    n_chans_in = meta.extractor
        property = "n_chans_mscan"
        module = dataset

    n_chans_out = meta.extractor
        property = "n_chans_msegm"
        module = dataset

predict = predict.sigmoid
    @init = false

model = model.model
    model_core = model_core
    predict = predict
    loss = loss.sigmoid_cross_entropy
        @init = false

    optimize = optimize.tf_optimize
        @init = false
        tf_optimizer_name = "AdamOptimizer"

frozen_model = model.frozen_model
    model_core = model_core
    predict = predict

model_controller = model_controller.model_controller
    model = model
    log_path = log_path

train = train.train_with_lr_decrease
    @init = false
    atol = 0.01
    lr_dec_mul = 0.7
    lr_init = 0.1
    n_epochs = 20
    patience = 5
    rtol = 0.03

    model_controller = model_controller
    train_batch_iter_factory = batch_iter_factory
    val_ids = val_ids
    load_x = load_x
    load_y = load_y
