model_core = model_core:unet2d
    channels = [64 128 256]

    n_chans_in = dataset.n_chans_mscan
    n_chans_out = dataset.n_chans_msegm

logits2pred = logits2pred:sigmoid
    @lazy

model = model:model
    model_core = model_core
    logits2pred = logits2pred
    logits2loss = logits2loss:sigmoid_cross_entropy(@lazy)
    optimize = optimize:tf_optimize
        @lazy
        tf_optimizer_name = "AdamOptimizer"

frozen_model = model:frozen_model
    model_core = model_core
    logits2pred = logits2pred
    restore_model_path = console.restore_model_path

train = train:train_msegm
    @lazy
    atol = 0.01
    lr_dec_mul = 0.7
    lr_init = 0.1
    n_epochs = n_epochs
    patience = 5
    rtol = 0.03
    log_path = console.log_path

    model = model
    train_batch_iter_factory = batch_iter_factory
    val_ids = val_ids
    dataset = dataset
    batch_predict = batch_predict

// commands

train_model = command:train_model
    train = train
    model = model
    save_model_path = console.save_model_path
    restore_model_path = console.restore_model_path

predict = command:predict
    ids = ids
    output_path = console.output_path
    load_x = load_x
    frozen_model = frozen_model
    batch_predict = batch_predict

compute_dices = command:compute_dices
    load_msegm = dataset.load_msegm
    predictions_path = console.predictions_path
    dices_path = console.dices_path

build_experiment = experiment:flat
    makefile = "train_msegm_threshold_eval"
    config_path = console.config_path
    experiment_path = console.experiment_path
    split = split

find_thresholds = command:find_dice_threshold
    load_msegm = dataset.load_msegm
    ids = ids
    predictions_path = console.predictions_path
    thresholds_path = thresholds_path

binarize = command:transform
    input_path = console.input_path
    output_path = console.output_path
    transform_fn = transform:binarize
        @lazy
        thresholds = io:json
            path = thresholds_path

thresholds_path = console.thresholds_path

// misc

batch_size = 20

load_x = dataset.load_mscan
load_y = dataset.load_msegm

console = io:console()

train_ids = io:json
    path = console.train_ids_path
val_ids = io:json
    path = console.val_ids_path
ids = io:json
    path = console.ids_path

// variants

dataset = dataset_wrapper:cached
    dataset = dataset_wrapper:normalized
        mean = true
        std = true
        dataset = dataset:csv_multi
            modalities = ["DWI" "Flair" "T1" "T2"]
            targets = ["OT"]
            data_path = data_path
            metadata_rpath = metadata_rpath

batch_iter_factory = batch_iter_factory:fin
    get_batch_iter = batch_iter:slices
        @lazy
        ids = train_ids
        load_x = load_x
        load_y = load_y
        batch_size = batch_size
        shuffle = true

split = split:cv_111
    n_splits = 5
    val_size = 5
    dataset = dataset

batch_predict = batch_predict:slice2d()

n_epochs = 2

data_path = "/nmnt/x04-hdd/ISLES/"
metadata_rpath = "siss2015.csv"
